---
title: "creating_merged_lipids"
output:
  workflowr::wflow_html:
    code_folding: hide
    toc: no
  html_notebook: default
  html_document:
    df_print: paged
    toc: no
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache= TRUE)
knitr::opts_chunk$set(autodep = TRUE)
```

## R Markdown

Here we will try to merge based on common chr.position (per Hg18) names.

```{r  create table,echo=FALSE,eval=FALSE}
library("data.table")
hdl=fread("~/lipids_mvp/data/Basic_mvp_sarah_HDL.tsv");
ldl=fread("~/lipids_mvp/data/Basic_mvp_sarah_LDL.tsv");
tc=fread("~/lipids_mvp/data/Basic_mvp_sarah_TC.tsv");
tg=fread("~/lipids_mvp/data/Basic_mvp_sarah_TG.tsv");
hdl=data.frame(hdl);ldl=data.frame(ldl);tc=data.frame(tc);tg=data.frame(tg)


## Creating Beta Table, merge by shared chromosome and base pair

m1 <- merge(hdl, ldl, by.x=c("hg19chrc", "bp"), by.y=c("hg19chrc", "bp"))
m2= merge(m1, tg, by.x=c("hg19chrc", "bp"), by.y=c("hg19chrc", "bp"))
m3= merge(m2, tc, by.x=c("hg19chrc", "bp"), by.y=c("hg19chrc", "bp"))

colnames(m3)[17]="tgsnp"
colnames(m3)[18]="tga1"
colnames(m3)[21]="tgp"
colnames(m3)[22]="tgbeta"
colnames(m3)[23]="tgSE"

colnames(m3)[24]="tcsnp"
colnames(m3)[25]="tca1"
colnames(m3)[27]="tcp"
colnames(m3)[29]="tcbeta"
colnames(m3)[30]="tcSE"


m3=m3[!duplicated(m3[,1:2]),] ###remove duplicated locations



betas=m3[,c("hg19chrc","bp","snpid.x","a1.x","beta.x","a1.y","beta.y","tga1","tgbeta","tca1","tcbeta")]
se=m3[,c("hg19chrc","bp","snpid.x","a1.x","stdErr.x","a1.y","stdErr.y","tga1","tgSE","tca1","tcSE")]
p=m3[,c("hg19chrc","bp","snpid.x","a1.x","p.x","a1.y","p.y","tga1","tgp","tca1","tcp")]



ref=betas[,"a1.x"] ###standardize to common reference allele for signing

m=betas

for(x in seq(1:3)){
  betaindex=5+2*x
  beta=m[,betaindex]
  allele=betaindex-1
  a=m[,allele]
  test=a==ref
  test[test=="FALSE"]=-1
  beta=beta*test
  m[,betaindex]=beta}

write.table(m,"~/lipids_mvp/data/merged_betas_mvp.txt")

num=m[,c(1,2,3,5,7,9,11)]
denom=se[,c(1,2,3,5,7,9,11)]
ptabl=p[,c(1,2,3,5,7,9,11)]

write.table(num,"~/lipids_mvp/data/merged_betas_mvp_simple.txt")##without alleles
write.table(denom,"~/lipids_mvp/data/merged_se_mvp_simple.txt")
write.table(ptabl,"~/lipids_mvp/data/merged_p_mvp_simple.txt")

z=num[,c(4:7)]/denom[,c(4:7)]
ztab=cbind(num[,c("hg19chrc","bp","snpid.x")],z)
write.table(z,"~/lipids_mvp/data/merged_z_mvp.txt")
      
write.table(ztab,"~/lipids_mvp/data/merged_z_mvp_withnames.txt")

```


To run mashr, we need a matrix of maxes. The best way to do this is to choose the max effect across conditions per LD block, as described in Pickrell et al. Only then can we assume the maxes used to create covariance matrices are truly linearly independent. We will select SNPS falling within each of the 1700 LD blocks and choose SNP with maximum absolute effect acrtoss conditions.

```{r zstuff,echo=T}

ztab=read.table("~/lipids_mvp/data/merged_z_mvp_withnames.txt")
bed=read.table("~/Downloads/ld_chunk.bed")
head(bed)

maxes=apply(ztab[,c("beta.x","beta.y","tgbeta","tcbeta")],1,function(x){max(abs(x))})
znew=cbind(ztab,maxes)
colnames(znew)[c(4:7)]=c("hdl","ldl","tg","tc")
```

```{r maxblock, eval=FALSE,echo=TRUE}

max_block=data.frame(matrix(ncol = ncol(znew), nrow = nrow(bed)))
colnames(max_block)=colnames(znew)
for(i in 1:nrow(bed)){
  chr=bed[i,1]
  start=bed[i,2]
  stop=bed[i,3]
  in_chrom=znew[znew$hg19chrc==chr,]
  goodguys=in_chrom[in_chrom$bp>start&in_chrom$bp<stop,]
 if(nrow(goodguys)>0) {
    z.max=which.max(goodguys[,"maxes"])
    z_good=goodguys[z.max,]
    } else {
      z_good=rep(0,ncol(max_block))
    }
  z_good=data.table(z_good,stringsAsFactors = T)
  z_good$hg19chrc=as.character(z_good$hg19chrc)
  z_good$snpid.x=as.character(z_good$snpid.x)
  max_block[i,]=z_good
  print(i)
}

max_block=na.omit(max_block)
write.table(max_block,"~/lipids_mvp/data/max_ld_block.txt")


###FOR UKBB
bed=read.table("~/Downloads/ld_chunk.bed")
z=readRDS("~/Dropbox/z_ukbb.rds")
s=str_split_fixed(rownames(z),pattern = ":",n = 3)
chr=paste0("chr",s[,1])
znew=data.frame(chr=chr,bp=as.numeric(as.character(s[,2])),z)
bad=which(znew$chr=="chrX")
z2=znew[-bad,]
z2$chr=factor(z2$chr)
z2$maxes=max(abs(z2[,c(3:6)]))
#max_block=data.frame(matrix(ncol = ncol(znew), nrow = nrow(bed)))

max=apply(z2[,c(3:6)],1,function(x){max(abs(x))})
z2$maxes=max

max.block=data.frame(NULL,NULL,NULL)

for(i in 1463:nrow(bed)){
  print(i)
  chr=bed[i,1]
  start=bed[i,2]
  stop=bed[i,3]
  in_chrom=z2[z2$chr==chr,]
  goodguys=in_chrom[in_chrom$bp>start&in_chrom$bp<stop,]
 if(nrow(goodguys)>0) {
    z.max=which.max(goodguys[,"maxes"])
    z_good=goodguys[z.max,]
    } else {
      z_good=rep(0,ncol(z2))###If block doesn't contain a SNP in UKBB
    }
  #z_good=data.table(z_good,stringsAsFactors = T)
  #z_good$chr=as.character(z_good$chr)
  #z_good$snp=as.character(z_good$bp)
  max.block=rbind(max.block,z_good)
  
}

max_block=na.omit(max.block)
write.table(max_block,"~/Dropbox//max_ld_block_ukbb.txt")






```

Now, we're ready to mash!
```{r mashblock,eval=F,warning=FALSE}
#ztab=read.table("~/lipids_mvp/data/merged_z_mvp_withnames.txt")
#znew=read.table("~/lipids_mvp/data/merged_z_mvp.txt")
#colnames(znew)=c("hdl","ldl","tg","tc")

znew=z2[,c(3:6)]

library("mashr")
library("flashr")
max_block=read.table("~/Dropbox//max_ld_block_ukbb.txt")
source('~/Dropbox/flashR.R')
# identify a random subset of 20000 tests
random.subset = sample(1:nrow(znew),40000)
zmash=as.matrix(znew[,c("hdl","ldl","tg","tc")])
data.temp = mash_set_data(zmash[random.subset,],alpha = 1)
Vhat = estimate_null_correlation_simple(data.temp)
saveRDS(Vhat,"~/Dropbox//ukbbVhat.rds")
library("lattice")
clrs = colorRampPalette((c("#D73027","#FC8D59","#FEE090","#FFFFBF", "#E0F3F8","#91BFDB","#4575B4")))(64)

print(levelplot(Vhat,col.regions = clrs,xlab = "",ylab = "",colorkey = TRUE,main="VHAT"))

rm(data.temp)
data.random = mash_set_data(zmash[random.subset,],alpha = 1,V=Vhat)

zmax=apply(max_block[,c(3:6)],2,function(x){as.numeric(x)});rownames(zmax)=rownames(max_block)

data.strong = mash_set_data(zmax,alpha = 1,V=Vhat)

U.pca = cov_pca(data.strong,3)
source("~/Downloads/flashscript.R")
U.flash=cov_flash(data.strong, non_canonical = TRUE)
X.center = apply(data.strong$Bhat, 2, function(x) x - mean(x))
U.ed = cov_ed(data.strong, c(U.flash, U.pca, list("XX" = t(X.center) %*% X.center / nrow(X.center))))
saveRDS(U.ed,"~/Dropbox/ukbbEDcov.Rds")

U.ed=readRDS("~/Dropbox/ukbbEDcov.Rds")
U.c = cov_canonical(data.random)

m = mash(data.random, Ulist = c(U.ed,U.c),outputlevel = 1)
saveRDS(m,"~/Dropbox/mfitukbb.rds")

########## refit covmats with ukbbdata##
z_ukbb=as.matrix(readRDS("~/ukbb/z_ukbb.rds"))
random.subset=sample(1:nrow(z_ukbb),40000)
data.temp = mash_set_data(zmash[random.subset,],alpha = 1)
Vhat = estimate_null_correlation_simple(data.temp)
saveRDS(Vhat,"~/ukbb/ukbbVHAT.rds")
rm(data.temp)

####
mfitMVP=readRDS("~/mfitMVP.rds")##get the matrices from the MVP fit since they used the maxes and the ED 
U.c = cov_canonical(data.random)

Vhat=readRDS("~/ukbb/ukbbVHAT.rds")
data.random = mash_set_data(z_ukbb[random.subset,],alpha = 1,V=Vhat)

###model fit with weights and matrices
m_mash_ukbb = mash(data.random, Ulist = mfitMVP$fitted_g$Ulist,outputlevel = 1)
m_bma_ukbb=mash(data.random, Ulist = U.c,outputlevel = 1)

saveRDS(m_mash_ukbb,"~/ukbb/m_mash_ukbb.rds")
saveRDS(m_bma_ukbb,"~/ukbb/m_ukbb_bma.rds")
```

Now, let's plot the patterns of sharing as the correlation matrix of the estimated covariance matrices..

```{r barplot, eval=T}

zmash=read.table("~/lipids_mvp/data/merged_z_mvp.txt")
colnames(zmash)=c("hdl","ldl","tg","tc")

m=readRDS("~/lipids_mvp/data/mfitMVP.rds")

k=length(m$fitted_g$Ulist)
l=length(m$fitted_g$grid)
pimat=matrix(m$fitted_g$pi[-1],nrow=l,byrow=T)
colnames(pimat)=names(m$fitted_g$pi)[2:(k+1)]
barplot(colSums(pimat),las=2)
library("lattice")
for(i in 1:8){
  z.num=as.matrix(cov2cor(m$fitted_g$Ulist[[i]]))
  colnames(z.num)=row.names(z.num)=colnames(zmash)
clrs = colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF", "#E0F3F8","#91BFDB","#4575B4")))(64)
z.num[lower.tri(z.num)] = NA
print(levelplot(z.num,col.regions = clrs,xlab = "",ylab = "",colorkey = TRUE,main=paste0(names(m$fitted_g$Ulist)[[i]])))
}
```

Now we can compute posteriors,

```{r posteriorblock, eval=FALSE,echo=TRUE}

mash.data=mash_set_data(zmash,V = Vhat,alpha = 1)

m$result=mash_compute_posterior_matrices(m, mash.data, algorithm.version = "Rcpp")
saveRDS(m,"~/lipids_mvp/data/mashresult_mvp.rds")
```

Let's take a look:

```{r}
m=readRDS("~/lipids_mvp/data/mashresult_mvp.rds")
head(m$result$PosteriorMean)
head(m$result$lfsr)

lfsr=m$result$lfsr
s=rowSums(lfsr<=0.05)

hist(s[s>1],freq=FALSE,main="Number of Conditions")




#ash.z=apply(zmash,2,function(x){ashr::ash(x,sebetahat = rep(1,length(x)))})
# ash.pm=matrix(nrow=nrow(zmash),ncol=ncol(zmash))
# ash.lf=matrix(nrow=nrow(zmash),ncol=ncol(zmash))
# 
# for(i in 1:ncol(zmash))
#   
# {
#   x=zmash[,i]
#   a=ashr::ash(x,sebetahat = rep(1,length(x)))
#   ash.pm[,i]=a$result$PosteriorMean
#   ash.lf[,i]=a$result$lfsr
#   print(i)
# }
# 
# 
# colnames(ash.pm)=colnames(ash.lf)=colnames(zmash)
# rownames(ash.pm)=rownames(ash.lf)=rownames(zmash)
# 
# write.table(ash.pm,"~/lipids_mvp/data/ash_pm.txt")
# write.table(ash.lf,"~/lipids_mvp/data/ash_lf.txt")

ash.lf=read.table("~/lipids_mvp/data/ash_lf.txt")

ptab=apply(zmash,2,function(x){2*pnorm(-abs(x))})
#write.table(ptab,"~/lipids_mvp/data/merged_p.txt")
sum(ash.lf<0.05)
sum(lfsr<0.05)
```

Here `r sum(ash.lf<0.05)` SNPS x Conditions are less than 0.05 using a univariate appropach and `r sum(lfsr<0.05)` are less than 0.05 with a joint approach, a roughly 250% increase. Furthermore, `r sum(s>0)` SNPS are significant in at least one condition wiht a juint approach, while `r sum(rowSums(ash.lf<0.05)>0)` with a univariate one.

```{r}
p=read.table("~/lipids_mvp/data/merged_p.txt")
library(knitr)
library(kableExtra)
dt <- cbind(c(paste("Bonferroni=",sum(p<=5e-8)),paste("univariate_ash=",sum(ash.lf<0.05)),paste("mv_mash=",sum(lfsr<0.05))))

dt <- cbind(c(sum(p<=5e-8),sum(ash.lf<0.05),sum(lfsr<0.05)))
dt=cbind(dt,c(sum(rowSums(p<=5e-8)>0),sum(rowSums(ash.lf<0.05)>0),sum(rowSums(lfsr<0.05)>0)))
rownames(dt)=c("Bonferroni","UnivariateAsh","Mash")
colnames(dt)=c("Overall All Associations","Per Snp, in at least one")           
              
kable(dt)
dt %>%
  kable() %>%
  kable_styling()

lfsr=readRDS("~/lipids_mvp/data/combined_lfsr_MVP.rds")
pm=readRDS("~/lipids_mvp/data/combined_pm_MVP.rds")
zmash=readRDS("~/lipids_mvp/data/zmash.rds")
ptab=2*pnorm(-abs(zmash))
sum(lfsr<0.05)
sum(ptab<5e-8)
r=sample(nrow(pm),100000)
plot(zmash[r,],pm[r,],xlab="MLE",ylab="MASH",main="MashEstimatesvsZ")


ukbbVHAT.rds
```

